{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4740a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import models\n",
    "from core import data \n",
    "import utils \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b795e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../different_cards\"\n",
    "device = \"cpu\"\n",
    "exp_dir = \"../../classifier_test\"\n",
    "\n",
    "utils.prepare_directory(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c19a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_titles = [\n",
    "        'lr',\n",
    "        'train_loss',\n",
    "        'val_loss',\n",
    "        'train_top1',\n",
    "        'val_top1',\n",
    "        'train_time',\n",
    "        'val_time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab1bb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 validation split from training\n",
      "115 training remains\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "datahandler = data.CardDataHandler(data_dir, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f461acc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created uniform sampler\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = datahandler.get_dataloaders(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a3dd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the convnet and optimizer\n",
    "model = models.ConvNet()\n",
    "\n",
    "lr = 0.0001\n",
    "momentum = 0.9\n",
    "wd = 1e-4\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc405bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(exp_dir, \"training_logs\")\n",
    "utils.prepare_directory(log_dir)\n",
    "logger = utils.Logger(log_dir, 'logs', logger_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d79189b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch_monitor:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A/Users/jasonzhang/opt/anaconda3/envs/taskTohsakaTorch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1623459044803/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\n",
      "training loop:   7%|▋         | 8/115 [00:04<01:05,  1.63it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:06<00:35,  2.81it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:07<00:24,  3.69it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:09<00:19,  4.33it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:10<00:15,  4.78it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:11<00:13,  5.14it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:13<00:10,  5.38it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:14<00:09,  5.58it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:15<00:07,  5.73it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:17<00:05,  5.85it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:18<00:04,  5.92it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:19<00:03,  5.96it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:20<00:01,  6.00it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:22<00:00,  5.99it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:23<00:00,  4.92it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:02<00:01,  3.05it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:12<00:00,  1.01it/s]\u001b[A\n",
      "epoch_monitor:  10%|█         | 1/10 [00:36<05:28, 36.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.15  val loss: 0.98 val acc: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:03<00:45,  2.34it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:04<00:27,  3.66it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:20,  4.47it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:07<00:16,  4.97it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:08<00:14,  5.32it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.55it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.72it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:12<00:08,  5.84it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:13<00:07,  5.92it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:15<00:05,  5.97it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:16<00:04,  6.00it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:17<00:03,  6.03it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:19<00:01,  6.06it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:20<00:00,  6.06it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:21<00:00,  5.34it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:03<00:01,  2.59it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:13<00:00,  1.03s/it]\u001b[A\n",
      "epoch_monitor:  20%|██        | 2/10 [01:11<04:45, 35.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.94  val loss: 0.85 val acc: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:03<00:50,  2.10it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:05<00:29,  3.40it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:21,  4.26it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:07<00:17,  4.80it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:09<00:14,  5.16it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.40it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.60it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:13<00:08,  5.72it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:14<00:07,  5.81it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:15<00:05,  5.87it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:17<00:04,  5.94it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:18<00:03,  5.98it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:19<00:01,  6.01it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:21<00:00,  6.01it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:22<00:00,  5.18it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:03<00:02,  2.08it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:14<00:00,  1.09s/it]\u001b[A\n",
      "epoch_monitor:  30%|███       | 3/10 [01:47<04:12, 36.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.77  val loss: 0.76 val acc: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:04<00:53,  2.00it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:05<00:30,  3.28it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:22,  4.14it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:08<00:17,  4.72it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:09<00:14,  5.13it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.42it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.62it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:13<00:08,  5.77it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:14<00:07,  5.86it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:15<00:05,  5.93it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:17<00:04,  5.91it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:18<00:03,  5.94it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:19<00:01,  5.98it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:21<00:00,  6.02it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:22<00:00,  5.17it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:02<00:01,  2.83it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:13<00:00,  1.01s/it]\u001b[A\n",
      "epoch_monitor:  40%|████      | 4/10 [02:23<03:34, 35.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.64  val loss: 0.54 val acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:03<00:50,  2.13it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:05<00:29,  3.39it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:21,  4.21it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:07<00:17,  4.70it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:09<00:14,  5.07it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.34it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.49it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:13<00:09,  5.62it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:14<00:07,  5.70it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:16<00:06,  5.80it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:17<00:04,  5.88it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:18<00:03,  5.92it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:19<00:01,  5.96it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:21<00:00,  5.98it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:22<00:00,  5.15it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:02<00:01,  2.82it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:13<00:00,  1.01s/it]\u001b[A\n",
      "epoch_monitor:  50%|█████     | 5/10 [02:59<02:58, 35.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.46  val loss: 0.45 val acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:03<00:46,  2.31it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:04<00:27,  3.63it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:20,  4.42it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:07<00:16,  4.92it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:08<00:14,  5.25it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.50it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.66it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:12<00:08,  5.78it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:14<00:07,  5.86it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:15<00:05,  5.92it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:16<00:04,  5.94it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:18<00:03,  5.97it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:19<00:01,  6.00it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:20<00:00,  6.01it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:21<00:00,  5.29it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:02<00:01,  2.80it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:13<00:00,  1.01s/it]\u001b[A\n",
      "epoch_monitor:  60%|██████    | 6/10 [03:34<02:21, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.52  val loss: 0.36 val acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:03<00:48,  2.20it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:04<00:28,  3.49it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:21,  4.29it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:07<00:17,  4.79it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:09<00:14,  5.12it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.35it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.51it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:13<00:09,  5.62it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:14<00:07,  5.69it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:15<00:06,  5.74it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:17<00:04,  5.76it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:18<00:03,  5.76it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:20<00:01,  5.79it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:21<00:00,  5.81it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:22<00:00,  5.12it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:03<00:01,  2.64it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:13<00:00,  1.02s/it]\u001b[A\n",
      "epoch_monitor:  70%|███████   | 7/10 [04:09<01:46, 35.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.36  val loss: 0.31 val acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:03<00:47,  2.26it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:04<00:27,  3.57it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:20,  4.40it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:07<00:16,  4.94it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:08<00:14,  5.16it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.37it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.58it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:12<00:08,  5.72it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:14<00:07,  5.83it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:15<00:05,  5.91it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:16<00:04,  5.97it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:18<00:03,  6.01it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:19<00:01,  6.04it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:20<00:00,  6.06it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:21<00:00,  5.27it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:03<00:01,  2.61it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:13<00:00,  1.02s/it]\u001b[A\n",
      "epoch_monitor:  80%|████████  | 8/10 [04:45<01:11, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.26  val loss: 0.27 val acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:03<00:48,  2.22it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:04<00:27,  3.54it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:20,  4.37it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:07<00:16,  4.92it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:08<00:14,  5.29it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.54it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.71it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:12<00:08,  5.83it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:14<00:07,  5.90it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:15<00:05,  5.95it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:16<00:04,  5.99it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:18<00:03,  6.03it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:19<00:01,  6.05it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:20<00:00,  6.02it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:21<00:00,  5.29it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:02<00:01,  2.92it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:12<00:00,  1.00it/s]\u001b[A\n",
      "epoch_monitor:  90%|█████████ | 9/10 [05:20<00:35, 35.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.28  val loss: 0.23 val acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "training loop:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "training loop:   7%|▋         | 8/115 [00:03<00:47,  2.23it/s]\u001b[A\n",
      "training loop:  14%|█▍        | 16/115 [00:04<00:27,  3.56it/s]\u001b[A\n",
      "training loop:  21%|██        | 24/115 [00:06<00:20,  4.39it/s]\u001b[A\n",
      "training loop:  28%|██▊       | 32/115 [00:07<00:16,  4.93it/s]\u001b[A\n",
      "training loop:  35%|███▍      | 40/115 [00:08<00:14,  5.29it/s]\u001b[A\n",
      "training loop:  42%|████▏     | 48/115 [00:10<00:12,  5.53it/s]\u001b[A\n",
      "training loop:  49%|████▊     | 56/115 [00:11<00:10,  5.71it/s]\u001b[A\n",
      "training loop:  56%|█████▌    | 64/115 [00:12<00:08,  5.83it/s]\u001b[A\n",
      "training loop:  63%|██████▎   | 72/115 [00:14<00:07,  5.92it/s]\u001b[A\n",
      "training loop:  70%|██████▉   | 80/115 [00:15<00:05,  5.95it/s]\u001b[A\n",
      "training loop:  77%|███████▋  | 88/115 [00:16<00:04,  5.94it/s]\u001b[A\n",
      "training loop:  83%|████████▎ | 96/115 [00:18<00:03,  5.99it/s]\u001b[A\n",
      "training loop:  90%|█████████ | 104/115 [00:19<00:01,  6.00it/s]\u001b[A\n",
      "training loop:  97%|█████████▋| 112/115 [00:20<00:00,  6.03it/s]\u001b[A\n",
      "training loop: 100%|██████████| 115/115 [00:21<00:00,  5.29it/s]\u001b[A\n",
      "\n",
      "val loop:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "val loop:  62%|██████▏   | 8/13 [00:02<00:01,  2.93it/s]\u001b[A\n",
      "val loop: 100%|██████████| 13/13 [00:12<00:00,  1.00it/s]\u001b[A\n",
      "epoch_monitor: 100%|██████████| 10/10 [05:54<00:00, 35.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.27  val loss: 0.20 val acc: 1.00\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "n_epochs = 10\n",
    "\n",
    "best_top1 = 0 \n",
    "best_confmat = None \n",
    "for epoch in trange(0, n_epochs, desc=\"epoch_monitor\", dynamic_ncols=False):\n",
    "    train_loss, train_top1, train_time = utils.train(model, trainloader, optimizer, criterion, device)\n",
    "    val_loss, val_top1, confmat, val_time = utils.evaluate(model, valloader, criterion, device)\n",
    "    \n",
    "    is_best = best_top1 < val_top1\n",
    "    if is_best:\n",
    "        best_top1 = val_top1\n",
    "        best_confmat = confmat\n",
    "        \n",
    "    utils.save_checkpoint({\n",
    "        'model': model.state_dict(),\n",
    "        'epoch': epoch, \n",
    "        'best_top1':best_top1,\n",
    "        'val_top1':val_top1}, \n",
    "        exp_dir,\n",
    "        is_best)\n",
    "    \n",
    "    logger.append(\n",
    "            [lr, train_loss, val_loss,\n",
    "            train_top1, val_top1,  \n",
    "            train_time, val_time],\n",
    "            epoch)\n",
    "\n",
    "    print(\"train loss: {:.2f}  val loss: {:.2f} val acc: {:.2f}\".format(train_loss, val_loss, val_top1))\n",
    "\n",
    "logger.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0a3cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 7]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deed075c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739130434782609"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c6969d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (extractor): Extractor(\n",
       "    (extractor): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fb899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimCheck():\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): \n",
    "        print(input)\n",
    "        print(len(input))\n",
    "        print(input[0])\n",
    "        print(type(input[0]))\n",
    "        print(\"input shape: {}\".format(input[0].size()))\n",
    "        print(\"output shape: {}\".format(output[0].size()))\n",
    "    def remove(self):\n",
    "        self.hook.remove() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7146ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[0.0000, 0.9823, 1.0330, 1.3835],\n",
      "          [0.0000, 0.6851, 0.2745, 1.3218],\n",
      "          [0.0000, 0.0000, 0.1472, 0.4133],\n",
      "          [0.0000, 0.0000, 0.3473, 0.3521]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6740, 0.3269, 0.3486, 1.0992],\n",
      "          [0.6895, 1.2781, 1.5976, 4.5500]],\n",
      "\n",
      "         [[0.0510, 0.6375, 0.0000, 0.1581],\n",
      "          [0.7643, 2.0497, 0.0902, 0.0000],\n",
      "          [0.4224, 0.2055, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.3856, 0.0000, 0.1156],\n",
      "          [0.0000, 0.9176, 0.9981, 0.8424],\n",
      "          [0.1459, 0.7396, 1.1426, 0.7488],\n",
      "          [0.0000, 0.6087, 1.0331, 1.4885]],\n",
      "\n",
      "         [[0.0000, 0.3155, 0.0000, 0.3677],\n",
      "          [0.0000, 0.0000, 0.0000, 1.1952],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.4405]],\n",
      "\n",
      "         [[0.0000, 0.1439, 0.3486, 0.9290],\n",
      "          [0.0000, 0.0000, 0.0000, 0.1002],\n",
      "          [0.0000, 0.2171, 0.0000, 0.0120],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2055, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0694],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7968, 0.5654, 0.0000, 0.0000],\n",
      "          [1.2361, 1.1001, 0.0000, 0.0148]],\n",
      "\n",
      "         [[1.5117, 1.8044, 0.8836, 0.5470],\n",
      "          [0.6404, 1.2653, 1.6858, 0.4726],\n",
      "          [0.5405, 1.2415, 1.6456, 1.6671],\n",
      "          [0.5116, 0.9806, 0.0279, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.2508, 0.1752, 0.0132],\n",
      "          [0.0000, 0.2395, 0.6839, 0.8800],\n",
      "          [0.0960, 0.7413, 0.5025, 0.8507],\n",
      "          [0.1757, 0.8469, 0.4919, 1.1162]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7059, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6323, 0.0000, 0.0000, 0.0535],\n",
      "          [0.2519, 0.3502, 0.4381, 0.1489]],\n",
      "\n",
      "         [[0.0845, 0.0000, 0.3755, 0.1091],\n",
      "          [0.0000, 0.1701, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.4246, 0.2531],\n",
      "          [0.0000, 0.0000, 0.0000, 0.7578],\n",
      "          [0.1261, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.3938]],\n",
      "\n",
      "         [[0.4802, 0.4142, 0.0000, 0.1682],\n",
      "          [2.3969, 1.2701, 0.0000, 0.0000],\n",
      "          [0.9528, 0.2299, 1.4432, 2.2777],\n",
      "          [0.5208, 0.0000, 2.5502, 3.5654]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0601, 1.3597],\n",
      "          [0.0000, 0.6190, 0.2940, 0.4549],\n",
      "          [0.0000, 0.9139, 0.5612, 0.2606]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0415, 1.3356, 0.2211, 0.4692],\n",
      "          [0.6589, 0.5101, 0.0575, 0.0443],\n",
      "          [0.0526, 0.7690, 0.4558, 0.5826],\n",
      "          [0.0000, 0.0000, 0.0000, 0.1395]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0241],\n",
      "          [0.3100, 0.4693, 0.3638, 0.8276],\n",
      "          [2.0473, 0.4150, 0.3315, 0.1984],\n",
      "          [2.6716, 1.2224, 0.8191, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.5635, 1.6587, 1.3159],\n",
      "          [0.0000, 0.1709, 1.5017, 1.8443],\n",
      "          [0.1089, 0.0000, 0.0000, 0.1318],\n",
      "          [0.4747, 0.0000, 0.0000, 0.4540]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.9823, 1.0330, 1.3835],\n",
      "          [0.0000, 0.6851, 0.2745, 1.3218],\n",
      "          [0.0000, 0.0000, 0.1472, 0.4133],\n",
      "          [0.0000, 0.0000, 0.3473, 0.3521]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6740, 0.3269, 0.3486, 1.0992],\n",
      "          [0.6895, 1.2781, 1.5976, 4.5500]],\n",
      "\n",
      "         [[0.0510, 0.6375, 0.0000, 0.1581],\n",
      "          [0.7643, 2.0497, 0.0902, 0.0000],\n",
      "          [0.4224, 0.2055, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.3856, 0.0000, 0.1156],\n",
      "          [0.0000, 0.9176, 0.9981, 0.8424],\n",
      "          [0.1459, 0.7396, 1.1426, 0.7488],\n",
      "          [0.0000, 0.6087, 1.0331, 1.4885]],\n",
      "\n",
      "         [[0.0000, 0.3155, 0.0000, 0.3677],\n",
      "          [0.0000, 0.0000, 0.0000, 1.1952],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.4405]],\n",
      "\n",
      "         [[0.0000, 0.1439, 0.3486, 0.9290],\n",
      "          [0.0000, 0.0000, 0.0000, 0.1002],\n",
      "          [0.0000, 0.2171, 0.0000, 0.0120],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[2.4837, 2.3552, 1.5064, 0.2761],\n",
      "          [2.9899, 2.2763, 1.4238, 0.7946],\n",
      "          [2.4983, 0.4034, 0.7925, 0.0000],\n",
      "          [1.7002, 0.0000, 0.3992, 0.0840]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.3657, 0.0075],\n",
      "          [0.0000, 0.0000, 0.3745, 0.9164],\n",
      "          [0.9755, 1.3742, 0.6281, 1.6267],\n",
      "          [2.1992, 1.0467, 1.1811, 1.7426]],\n",
      "\n",
      "         [[1.9563, 3.1016, 3.5431, 2.4220],\n",
      "          [0.8850, 2.7243, 2.5885, 1.9753],\n",
      "          [0.5623, 0.3583, 0.4683, 0.7346],\n",
      "          [0.8538, 0.5649, 0.7753, 0.6790]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.3289, 0.9471, 0.0000, 0.0000],\n",
      "          [0.2634, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6086, 0.5747, 0.0000],\n",
      "          [0.3952, 0.0062, 0.2558, 0.2313]],\n",
      "\n",
      "         [[0.4669, 0.0000, 0.0000, 0.2262],\n",
      "          [0.6821, 1.1851, 0.2840, 0.8208],\n",
      "          [0.0000, 0.6381, 1.0434, 1.5267],\n",
      "          [0.0000, 0.4006, 0.4449, 1.3239]],\n",
      "\n",
      "         [[0.9168, 1.0432, 0.6899, 0.3055],\n",
      "          [1.3974, 1.2359, 1.0563, 0.8531],\n",
      "          [2.0834, 0.5666, 0.2976, 0.8380],\n",
      "          [1.9533, 0.9424, 0.2319, 0.3069]]],\n",
      "\n",
      "\n",
      "        [[[0.3932, 0.6644, 0.4664, 0.2456],\n",
      "          [0.4579, 0.5890, 0.0000, 0.0000],\n",
      "          [0.0808, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0137, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0772, 0.0000, 0.0778, 0.0000],\n",
      "          [0.0129, 0.2552, 0.5120, 0.7853]],\n",
      "\n",
      "         [[0.3787, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0771, 0.1944],\n",
      "          [0.0000, 0.0000, 0.0000, 0.2013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0414],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1223, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0974, 0.0000],\n",
      "          [0.1261, 0.9596, 0.7861, 0.0000],\n",
      "          [0.1880, 0.4080, 0.0632, 0.0000],\n",
      "          [0.0000, 0.0286, 0.0000, 0.3229]],\n",
      "\n",
      "         [[0.0000, 0.2082, 0.2317, 0.2170],\n",
      "          [0.0000, 0.2846, 0.3580, 0.1195],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<ReluBackward1>),)\n",
      "1\n",
      "tensor([[[[0.0000, 0.9823, 1.0330, 1.3835],\n",
      "          [0.0000, 0.6851, 0.2745, 1.3218],\n",
      "          [0.0000, 0.0000, 0.1472, 0.4133],\n",
      "          [0.0000, 0.0000, 0.3473, 0.3521]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6740, 0.3269, 0.3486, 1.0992],\n",
      "          [0.6895, 1.2781, 1.5976, 4.5500]],\n",
      "\n",
      "         [[0.0510, 0.6375, 0.0000, 0.1581],\n",
      "          [0.7643, 2.0497, 0.0902, 0.0000],\n",
      "          [0.4224, 0.2055, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.3856, 0.0000, 0.1156],\n",
      "          [0.0000, 0.9176, 0.9981, 0.8424],\n",
      "          [0.1459, 0.7396, 1.1426, 0.7488],\n",
      "          [0.0000, 0.6087, 1.0331, 1.4885]],\n",
      "\n",
      "         [[0.0000, 0.3155, 0.0000, 0.3677],\n",
      "          [0.0000, 0.0000, 0.0000, 1.1952],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.4405]],\n",
      "\n",
      "         [[0.0000, 0.1439, 0.3486, 0.9290],\n",
      "          [0.0000, 0.0000, 0.0000, 0.1002],\n",
      "          [0.0000, 0.2171, 0.0000, 0.0120],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2055, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0694],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7968, 0.5654, 0.0000, 0.0000],\n",
      "          [1.2361, 1.1001, 0.0000, 0.0148]],\n",
      "\n",
      "         [[1.5117, 1.8044, 0.8836, 0.5470],\n",
      "          [0.6404, 1.2653, 1.6858, 0.4726],\n",
      "          [0.5405, 1.2415, 1.6456, 1.6671],\n",
      "          [0.5116, 0.9806, 0.0279, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.2508, 0.1752, 0.0132],\n",
      "          [0.0000, 0.2395, 0.6839, 0.8800],\n",
      "          [0.0960, 0.7413, 0.5025, 0.8507],\n",
      "          [0.1757, 0.8469, 0.4919, 1.1162]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7059, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6323, 0.0000, 0.0000, 0.0535],\n",
      "          [0.2519, 0.3502, 0.4381, 0.1489]],\n",
      "\n",
      "         [[0.0845, 0.0000, 0.3755, 0.1091],\n",
      "          [0.0000, 0.1701, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.4246, 0.2531],\n",
      "          [0.0000, 0.0000, 0.0000, 0.7578],\n",
      "          [0.1261, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.3938]],\n",
      "\n",
      "         [[0.4802, 0.4142, 0.0000, 0.1682],\n",
      "          [2.3969, 1.2701, 0.0000, 0.0000],\n",
      "          [0.9528, 0.2299, 1.4432, 2.2777],\n",
      "          [0.5208, 0.0000, 2.5502, 3.5654]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0601, 1.3597],\n",
      "          [0.0000, 0.6190, 0.2940, 0.4549],\n",
      "          [0.0000, 0.9139, 0.5612, 0.2606]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0415, 1.3356, 0.2211, 0.4692],\n",
      "          [0.6589, 0.5101, 0.0575, 0.0443],\n",
      "          [0.0526, 0.7690, 0.4558, 0.5826],\n",
      "          [0.0000, 0.0000, 0.0000, 0.1395]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0241],\n",
      "          [0.3100, 0.4693, 0.3638, 0.8276],\n",
      "          [2.0473, 0.4150, 0.3315, 0.1984],\n",
      "          [2.6716, 1.2224, 0.8191, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.5635, 1.6587, 1.3159],\n",
      "          [0.0000, 0.1709, 1.5017, 1.8443],\n",
      "          [0.1089, 0.0000, 0.0000, 0.1318],\n",
      "          [0.4747, 0.0000, 0.0000, 0.4540]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.9823, 1.0330, 1.3835],\n",
      "          [0.0000, 0.6851, 0.2745, 1.3218],\n",
      "          [0.0000, 0.0000, 0.1472, 0.4133],\n",
      "          [0.0000, 0.0000, 0.3473, 0.3521]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6740, 0.3269, 0.3486, 1.0992],\n",
      "          [0.6895, 1.2781, 1.5976, 4.5500]],\n",
      "\n",
      "         [[0.0510, 0.6375, 0.0000, 0.1581],\n",
      "          [0.7643, 2.0497, 0.0902, 0.0000],\n",
      "          [0.4224, 0.2055, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.3856, 0.0000, 0.1156],\n",
      "          [0.0000, 0.9176, 0.9981, 0.8424],\n",
      "          [0.1459, 0.7396, 1.1426, 0.7488],\n",
      "          [0.0000, 0.6087, 1.0331, 1.4885]],\n",
      "\n",
      "         [[0.0000, 0.3155, 0.0000, 0.3677],\n",
      "          [0.0000, 0.0000, 0.0000, 1.1952],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.4405]],\n",
      "\n",
      "         [[0.0000, 0.1439, 0.3486, 0.9290],\n",
      "          [0.0000, 0.0000, 0.0000, 0.1002],\n",
      "          [0.0000, 0.2171, 0.0000, 0.0120],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[2.4837, 2.3552, 1.5064, 0.2761],\n",
      "          [2.9899, 2.2763, 1.4238, 0.7946],\n",
      "          [2.4983, 0.4034, 0.7925, 0.0000],\n",
      "          [1.7002, 0.0000, 0.3992, 0.0840]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.3657, 0.0075],\n",
      "          [0.0000, 0.0000, 0.3745, 0.9164],\n",
      "          [0.9755, 1.3742, 0.6281, 1.6267],\n",
      "          [2.1992, 1.0467, 1.1811, 1.7426]],\n",
      "\n",
      "         [[1.9563, 3.1016, 3.5431, 2.4220],\n",
      "          [0.8850, 2.7243, 2.5885, 1.9753],\n",
      "          [0.5623, 0.3583, 0.4683, 0.7346],\n",
      "          [0.8538, 0.5649, 0.7753, 0.6790]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.3289, 0.9471, 0.0000, 0.0000],\n",
      "          [0.2634, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6086, 0.5747, 0.0000],\n",
      "          [0.3952, 0.0062, 0.2558, 0.2313]],\n",
      "\n",
      "         [[0.4669, 0.0000, 0.0000, 0.2262],\n",
      "          [0.6821, 1.1851, 0.2840, 0.8208],\n",
      "          [0.0000, 0.6381, 1.0434, 1.5267],\n",
      "          [0.0000, 0.4006, 0.4449, 1.3239]],\n",
      "\n",
      "         [[0.9168, 1.0432, 0.6899, 0.3055],\n",
      "          [1.3974, 1.2359, 1.0563, 0.8531],\n",
      "          [2.0834, 0.5666, 0.2976, 0.8380],\n",
      "          [1.9533, 0.9424, 0.2319, 0.3069]]],\n",
      "\n",
      "\n",
      "        [[[0.3932, 0.6644, 0.4664, 0.2456],\n",
      "          [0.4579, 0.5890, 0.0000, 0.0000],\n",
      "          [0.0808, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0137, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0772, 0.0000, 0.0778, 0.0000],\n",
      "          [0.0129, 0.2552, 0.5120, 0.7853]],\n",
      "\n",
      "         [[0.3787, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0771, 0.1944],\n",
      "          [0.0000, 0.0000, 0.0000, 0.2013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0414],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1223, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0974, 0.0000],\n",
      "          [0.1261, 0.9596, 0.7861, 0.0000],\n",
      "          [0.1880, 0.4080, 0.0632, 0.0000],\n",
      "          [0.0000, 0.0286, 0.0000, 0.3229]],\n",
      "\n",
      "         [[0.0000, 0.2082, 0.2317, 0.2170],\n",
      "          [0.0000, 0.2846, 0.3580, 0.1195],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<ReluBackward1>)\n",
      "<class 'torch.Tensor'>\n",
      "input shape: torch.Size([8, 2048, 4, 4])\n",
      "output shape: torch.Size([2048, 1, 1])\n",
      "torch.Size([8, 2048])\n"
     ]
    }
   ],
   "source": [
    "for image, label in trainloader:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device, non_blocking=True)\n",
    "        \n",
    "        output1 = model.extractor(image)\n",
    "        \n",
    "        print(output1.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d401d017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool2d(output_size=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "avg2dfinal_layer = model.extractor.extractor[8]\n",
    "print(avg2dfinal_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35b66800",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = DimCheck(avg2dfinal_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f91ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ac259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
